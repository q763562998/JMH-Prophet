{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time as nowtime\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GraphUNet, global_mean_pool, GATConv\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch_geometric.utils import barabasi_albert_graph\n",
    "import networkx as nx\n",
    "import pickle as pkl\n",
    "import random\n",
    "import numpy as np\n",
    "import torch_geometric.transforms as T\n",
    "from typing import Optional, Callable\n",
    "\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GCN\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch_geometric.nn import GCNConv,global_max_pool, GATConv, GATv2Conv,GraphSAGE,SAGEConv\n",
    "\n",
    "\n",
    "from torch_geometric.nn import GraphConv,global_mean_pool,global_add_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import math\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.nn import GCN\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch_geometric.nn import GCNConv,global_max_pool, GATConv, GATv2Conv,GraphSAGE,SAGEConv\n",
    "\n",
    "\n",
    "from torch_geometric.nn import GraphConv,global_mean_pool,global_add_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import networkx as nx\n",
    "import numpy as np \n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch_geometric\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from datetime import datetime\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GraphUNet, global_mean_pool, GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    names, namelen, tokns_list, graphs_list, labels,ori_key_list = zip(*batch)\n",
    "\n",
    "\n",
    "    names_batch = torch.tensor(names, dtype=torch.long)\n",
    "    namelen_batch = torch.tensor(namelen, dtype=torch.long)\n",
    "    tokns_batch = torch_geometric.data.Batch.from_data_list(tokns_list)\n",
    "    graphs_batch = torch_geometric.data.Batch.from_data_list(graphs_list)\n",
    "    labels_batch = torch.stack([torch.tensor(l, dtype=torch.double) for l in labels], dim=0)\n",
    "    method_batch= ori_key_list\n",
    "\n",
    "\n",
    "    return names_batch, namelen_batch, tokns_batch, graphs_batch, labels_batch,method_batch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BOWEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size):\n",
    "        super(BOWEncoder, self).__init__()\n",
    "        self.emb_size=emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        nn.init.uniform_(self.embedding.weight, -0.1, 0.1)\n",
    "        nn.init.constant_(self.embedding.weight[0], 0)\n",
    "        \n",
    "    def forward(self, input, input_len=None): \n",
    "        batch_size, seq_len =input.size()\n",
    "        embedded = self.embedding(input)\n",
    "        embedded= F.dropout(embedded, 0.25, self.training)\n",
    "        \n",
    "        # max pooling word vectors\n",
    "        output_pool = F.max_pool1d(embedded.transpose(1,2), seq_len).squeeze(2) # [batch_size x emb_size]\n",
    "        encoding = output_pool #torch.tanh(output_pool)        \n",
    "        return encoding\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  \n",
    "        self.relu = nn.ReLU()  \n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x.float())\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, num_layers):\n",
    "        super(MultiModel, self).__init__()\n",
    "        pool_ratios = 0.6\n",
    "        self.tree_conv1 = GraphUNet(13,out_channels ,hidden_channels,num_layers,pool_ratios)\n",
    "        self.graph_conv1 = GraphUNet(20, out_channels, hidden_channels, num_layers, pool_ratios)\n",
    "        \n",
    "\n",
    "        vocab_size = 200000\n",
    "        emb_size = 512\n",
    "        hidden_size = 256\n",
    "        self.encoder=BOWEncoder(vocab_size, emb_size, hidden_size)\n",
    "        \n",
    "        self.my_encoder=MyModel(16,hidden_size,emb_size)\n",
    "\n",
    "\n",
    "        self.lin1=torch.nn.Linear(hidden_channels,out_channels)\n",
    "        self.lin2=torch.nn.Linear(out_channels,512)\n",
    "        self.hidden=512\n",
    "\n",
    "        self.tree_gat1 = GATConv(hidden_channels, hidden_channels, heads=1, concat=False)\n",
    "        self.graph_gat1 = GATConv(hidden_channels, hidden_channels, heads=1, concat=False)\n",
    "\n",
    "\n",
    "        self.lin3 = torch.nn.Linear(hidden_channels, 512)\n",
    "\n",
    "        lstm_dims=256\n",
    "        n_hidden=512\n",
    "        emb_size=512\n",
    "\n",
    "\n",
    "        self.w_name = nn.Linear(2*lstm_dims, n_hidden)\n",
    "        self.w_tok = nn.Linear(emb_size, n_hidden)\n",
    "        self.w_graphseq=nn.Linear(2*lstm_dims, n_hidden)  \n",
    "        self.w_desc = nn.Linear(2*lstm_dims, n_hidden)\n",
    "        \n",
    "        self.w_atten = nn.Linear(n_hidden, 1)\n",
    "        self.fuse = nn.Linear(n_hidden*3,n_hidden)\n",
    "        self.fuse4 = nn.Linear(n_hidden*4,n_hidden)\n",
    "        self.init_weights()\n",
    "\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.fc4 = nn.Linear(512, 1)\n",
    "\n",
    "        self.drop1=torch.nn.Dropout()\n",
    "        self.drop2=torch.nn.Dropout()\n",
    "    def init_weights(self):# Initialize Linear Weight \n",
    "        for m in [self.w_name, self.w_tok, self.w_graphseq, self.w_desc, self.w_atten, self.fuse]:        \n",
    "            m.weight.data.uniform_(-0.1, 0.1)#nn.init.xavier_normal_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0.)\n",
    "\n",
    "\n",
    "    def code_encoding(self, name_repr, tok_repr, graphseq_repr):\n",
    "\n",
    "        batch_size=name_repr.shape[0]\n",
    "       \n",
    "\n",
    "        name_feat_hidden = self.w_name(name_repr).reshape(-1, self.hidden)\n",
    "        tok_feat_hidden = self.w_tok(tok_repr).reshape(-1, self.hidden)\n",
    "        graphseq_feat_hidden = self.w_graphseq(graphseq_repr).reshape(-1, self.hidden)\n",
    "        name_attn_tanh = torch.tanh(name_feat_hidden)\n",
    "        name_attn_scalar = self.w_atten(F.dropout(name_attn_tanh, 0.25 ,self.training).reshape(-1, self.hidden))            \n",
    "        \n",
    "        tok_attn_tanh = torch.tanh(tok_feat_hidden)\n",
    "        tok_attn_scalar = self.w_atten(F.dropout(tok_attn_tanh, 0.25 ,self.training).reshape(-1, self.hidden))\n",
    "        \n",
    "        graphseq_attn_tanh = torch.tanh(graphseq_feat_hidden)\n",
    "        graphseq_attn_scalar = self.w_atten(F.dropout(graphseq_attn_tanh, 0.25 ,self.training).reshape(-1, self.hidden))\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        attn_cat = torch.cat([name_attn_scalar, tok_attn_scalar, graphseq_attn_scalar], 1)\n",
    "        \n",
    "        atten_weight = torch.sigmoid(attn_cat)\n",
    "\n",
    "\n",
    "        name_feat_atten = torch.bmm(atten_weight[:,0].reshape(batch_size, 1, 1),name_repr.reshape(batch_size, 1, self.hidden))     \n",
    "        tok_feat_atten = torch.bmm(atten_weight[:,0].reshape(batch_size, 1, 1),tok_repr.reshape(batch_size, 1, self.hidden))\n",
    "        graphseq_feat_atten = torch.bmm(atten_weight[:,0].reshape(batch_size, 1, 1),graphseq_repr.reshape(batch_size, 1, self.hidden))\n",
    "\n",
    "        cat_atten_repr = torch.cat((name_feat_atten, tok_feat_atten, graphseq_feat_atten), 2)\n",
    "        code_repr = torch.tanh(self.fuse(F.dropout(cat_atten_repr, 0.25, training=self.training))).reshape(-1,self.hidden)\n",
    "        return code_repr \n",
    "\n",
    "    def four_modal_fusion(self, name_repr, tok_repr, graphseq_repr, audio_repr):\n",
    "        batch_size = name_repr.shape[0]\n",
    "\n",
    "        name_feat_hidden = self.w_name(name_repr).reshape(-1, self.hidden)\n",
    "        tok_feat_hidden = self.w_tok(tok_repr).reshape(-1, self.hidden)\n",
    "        graphseq_feat_hidden = self.w_graphseq(graphseq_repr).reshape(-1, self.hidden)\n",
    "        audio_feat_hidden = self.w_audio(audio_repr).reshape(-1, self.hidden)\n",
    "\n",
    "        name_attn_tanh = torch.tanh(name_feat_hidden)\n",
    "        name_attn_scalar = self.w_atten(F.dropout(name_attn_tanh, 0.25, self.training).reshape(-1, self.hidden))\n",
    "\n",
    "        tok_attn_tanh = torch.tanh(tok_feat_hidden)\n",
    "        tok_attn_scalar = self.w_atten(F.dropout(tok_attn_tanh, 0.25, self.training).reshape(-1, self.hidden))\n",
    "\n",
    "        graphseq_attn_tanh = torch.tanh(graphseq_feat_hidden)\n",
    "        graphseq_attn_scalar = self.w_atten(F.dropout(graphseq_attn_tanh, 0.25, self.training).reshape(-1, self.hidden))\n",
    "\n",
    "        audio_attn_tanh = torch.tanh(audio_feat_hidden)\n",
    "        audio_attn_scalar = self.w_atten(F.dropout(audio_attn_tanh, 0.25, self.training).reshape(-1, self.hidden))\n",
    "\n",
    "        attn_cat = torch.cat([name_attn_scalar, tok_attn_scalar, graphseq_attn_scalar, audio_attn_scalar], 1)\n",
    "        atten_weight = F.softmax(attn_cat, dim=1)\n",
    "\n",
    "        name_feat_atten = torch.bmm(atten_weight[:, 0].reshape(batch_size, 1, 1), name_repr.reshape(batch_size, 1, self.hidden))\n",
    "        tok_feat_atten = torch.bmm(atten_weight[:, 0].reshape(batch_size, 1, 1), tok_repr.reshape(batch_size, 1, self.hidden))\n",
    "        graphseq_feat_atten = torch.bmm(atten_weight[:, 0].reshape(batch_size, 1, 1), graphseq_repr.reshape(batch_size, 1, self.hidden))\n",
    "        audio_feat_atten = torch.bmm(atten_weight[:, 0].reshape(batch_size, 1, 1), audio_repr.reshape(batch_size, 1, self.hidden))\n",
    "\n",
    "        cat_atten_repr = torch.cat((name_feat_atten, tok_feat_atten, graphseq_feat_atten, audio_feat_atten), 2)\n",
    "\n",
    "        # Perform further fusion and get the final representation\n",
    "        code_repr = torch.tanh(self.fuse(F.dropout(cat_atten_repr, 0.25, training=self.training))).reshape(-1, self.hidden)\n",
    "        return code_repr\n",
    "\n",
    "    def forward(self, name, namelen,tree_x,tree_edge_index,tree_batch,graph_x,graph_edge_index,graph_batch):\n",
    "        \n",
    "\n",
    "        name_repr=self.encoder(name,namelen) \n",
    "\n",
    "          \n",
    "        # name_repr= self.my_encoder(name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        tree_x=self.tree_conv1(tree_x,tree_edge_index,tree_batch)\n",
    "        tree_x=self.tree_gat1(tree_x,tree_edge_index)\n",
    "        tree_x=F.relu(tree_x)\n",
    "        tree_x=self.drop1(tree_x)\n",
    "\n",
    "        tree_x=self.lin3(tree_x)\n",
    "        \n",
    "        tree_x=global_mean_pool(tree_x,tree_batch)\n",
    "\n",
    "        tok_repr = tree_x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        graph_x=self.graph_conv1(graph_x,graph_edge_index,graph_batch)\n",
    "        graph_x=self.graph_gat1(graph_x,graph_edge_index)\n",
    "        graph_x=F.relu(graph_x)\n",
    "        graph_x=self.drop2(graph_x)\n",
    "\n",
    "        graph_x=self.lin3(graph_x)\n",
    "        graph_x=global_mean_pool(graph_x,graph_batch)\n",
    "        \n",
    "        graphseq_repr = graph_x\n",
    "       \n",
    "\n",
    "        # x=self.lin3(x)\n",
    "        x=self.code_encoding(name_repr,tok_repr,graphseq_repr)\n",
    "\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "\n",
    "        \n",
    "        return torch.tanh(self.fc3(x))  \n",
    "\n",
    "\n",
    "    def my_sigm(x):\n",
    "        \n",
    "        return 1 / (1+torch.exp(-2*x))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "        # device =  'cpu'\n",
    "out_channels=256\n",
    "hidden_channels=256\n",
    "num_layers=3\n",
    "model = MultiModel(1, out_channels, hidden_channels, num_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myname='crate'\n",
    "\n",
    "model.load_state_dict(torch.load('/home/zhs/predict/0110model/qianyi/qianyimodel/0113no'+myname+'.pth'))\n",
    "\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_path=\"/home/zhs/predict/expertcode/data/tn.json\"\n",
    "with open(json_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "with open(\"/home/zhs/predict/model/project_keywords.json\", \"r\") as file:\n",
    "    project_keywords = json.load(file)\n",
    "\n",
    "\n",
    "ori_key_list=[]\n",
    "ori_body_list=[]\n",
    "ori_len_list=[]\n",
    "ori_tree_list=[]\n",
    "ori_cfg_list=[]\n",
    "ori_lables_list=[]\n",
    "\n",
    "\n",
    "tree_batch = torch.load('/home/zhs/predict/expertcode/data/all_tree.pt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cfg_batch = torch.load('/home/zhs/predict/expertcode/data/all_cfg.pt')\n",
    "\n",
    "len(cfg_batch)\n",
    "len(tree_batch)\n",
    "\n",
    "\n",
    "time=1\n",
    "\n",
    "for key in data.keys():\n",
    "\n",
    "    value = json.loads(data[key])\n",
    "    key=key.split(\"#\")[0]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    if not  any(keyword in key for keyword in project_keywords[myname]):\n",
    "        continue\n",
    "\n",
    "    # print(key)\n",
    "    \n",
    "    size=value.get(\"len\")\n",
    "    body=value.get(\"indexList\")\n",
    "    lables=value.get(\"lables\")\n",
    "    # 要求lables 不是null\n",
    "    if lables==None :\n",
    "        continue\n",
    "\n",
    "    d=0\n",
    "    \n",
    "    for tree in tree_batch:\n",
    "\n",
    "        if tree.y==key:\n",
    "            d=1\n",
    "            # ori_tree_list.append(tree)\n",
    "            t=tree\n",
    "            continue\n",
    "    # if d==0:\n",
    "    #     print(key)\n",
    "    c=0    \n",
    "    for cfg in cfg_batch:\n",
    "        if cfg.y==key:\n",
    "            # print(key)\n",
    "            c=1\n",
    "            # ori_cfg_list.append(cfg)\n",
    "            g=cfg\n",
    "            continue\n",
    "    if c==1 & d ==1:\n",
    "\n",
    "        ori_key_list.append(key)\n",
    "        ori_len_list.append(size)\n",
    "        ori_body_list.append(body)\n",
    "        ori_lables_list.append(lables)\n",
    "        ori_cfg_list.append(g)\n",
    "        ori_tree_list.append(t)\n",
    "        \n",
    "    time=time-1\n",
    "\n",
    "names = ori_body_list\n",
    "\n",
    "namelen =ori_len_list\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labels=list(map(float, ori_lables_list))\n",
    "\n",
    "\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "normalized_labels = (labels - labels.min()) / (labels.max() - labels.min())\n",
    "\n",
    "\n",
    "\n",
    "# print(normalized_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "log_array = [math.log(x + 1) for x in labels]\n",
    "\n",
    "\n",
    "max_value = max(log_array)\n",
    "\n",
    "\n",
    "normalized_array = [x / max_value for x in log_array]\n",
    "\n",
    "\n",
    "\n",
    "labels=torch.tensor(normalized_labels)\n",
    "# labels=list(map(float, ori_lables_list))\n",
    "# print(labels)\n",
    "labels=normalized_array\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MultiModalDataset(object):\n",
    "    def __init__(self, names,namelen, tokns_list, graphs_list, labels,ori_key_list):\n",
    "\n",
    "        self.names = names\n",
    "        self.namelen=namelen\n",
    "        self.tokns_list = tokns_list\n",
    "        \n",
    "        self.graphs_list = graphs_list\n",
    "        \n",
    "        self.labels = labels\n",
    "        self.method = ori_key_list\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.names[idx] , self.namelen[idx] , self.tokns_list[idx] , self.graphs_list[idx] , self.labels[idx],self.method[idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming names, toks, graphseqs, labels are your data\n",
    "dataset = MultiModalDataset(names,namelen, ori_tree_list, ori_cfg_list, labels,ori_key_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(names))\n",
    "print(len(ori_cfg_list))\n",
    "ori_key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(train_loader):\n",
    "     \n",
    "    model.train()\n",
    "    optimizer.zero_grad(device)\n",
    "\n",
    "    total_loss = 0\n",
    "    for names_batch, namelen_batch, tokns_batch, graphs_batch, labels_batch,method in train_loader:\n",
    "        # print(\"starttrain\")\n",
    "        # print(method)\n",
    "        names_batch=names_batch.to(device)\n",
    "        namelen_batch=namelen_batch.to(device)\n",
    "        tokns_batch=tokns_batch.to(device)\n",
    "        graphs_batch=graphs_batch.to(device)\n",
    "        labels_batch=labels_batch.to(device)\n",
    "        # names_batch=names_batch.cuda()\n",
    "        # namelen_batch=namelen_batch.cuda()\n",
    "        # tokns_batch=tokns_batch.cuda()\n",
    "        tokns_batch.x=tokns_batch.x.to(device)\n",
    "        tokns_batch.edge_index=tokns_batch.edge_index.to(device)\n",
    "        tokns_batch.batch=tokns_batch.batch.to(device)\n",
    "        # graphs_batch=graphs_batch.cuda()\n",
    "        # labels_batch=labels_batch.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output=model(names_batch,namelen_batch,\n",
    "            tokns_batch.x,tokns_batch.edge_index,tokns_batch.batch,\n",
    "            graphs_batch.x,graphs_batch.edge_index,graphs_batch.batch)\n",
    "\n",
    "\n",
    "        y = labels_batch.view(-1, 1).float()\n",
    "        loss = F.mse_loss(output, y)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += float(loss) * len(namelen_batch)\n",
    "        \n",
    "\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader,my_size):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    preds = []\n",
    "    reals = []\n",
    "    for names_batch, namelen_batch, tokns_batch, graphs_batch, labels_batch ,method in loader:\n",
    "        # print(\"starttest\")\n",
    "        start_time = nowtime.time()  \n",
    "        names_batch=names_batch.to(device)\n",
    "        namelen_batch=namelen_batch.to(device)\n",
    "        \n",
    "        tokns_batch.x=tokns_batch.x.to(device)\n",
    "        tokns_batch.edge_index=tokns_batch.edge_index.to(device)\n",
    "        tokns_batch.batch=tokns_batch.batch.to(device)\n",
    "\n",
    "        graphs_batch.x=graphs_batch.x.to(device)\n",
    "        graphs_batch.edge_index=graphs_batch.edge_index.to(device)\n",
    "        graphs_batch.batch=graphs_batch.batch.to(device)\n",
    "\n",
    "        labels_batch=labels_batch.to(device)\n",
    "        \n",
    "        output=model(names_batch,namelen_batch,\n",
    "            tokns_batch.x,tokns_batch.edge_index,tokns_batch.batch,\n",
    "            graphs_batch.x,graphs_batch.edge_index,graphs_batch.batch)\n",
    "        \n",
    "\n",
    "        end_time = nowtime.time()  \n",
    "        eval_time = end_time - start_time  \n",
    "        print(method)\n",
    "        print(f\"Evaluation time for one data point: {eval_time} seconds\")\n",
    "\n",
    "        # loss = F.mse_loss(out,torch.reshape(data.y, (data.y.shape[0],1)))\n",
    "        y = labels_batch.view(-1, 1).float()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        loss = F.mse_loss(output, y)\n",
    "\n",
    "        total_loss += float(loss) * len(namelen_batch)\n",
    "        \n",
    "\n",
    "        pred=output.detach().cpu().numpy()\n",
    "        \n",
    "\n",
    "        real=y.detach().cpu().numpy()\n",
    "        \n",
    "        preds = np.concatenate((preds,pred.flatten() ), axis=0)\n",
    "        reals = np.concatenate((reals, real.flatten()), axis=0)\n",
    "\n",
    "         \n",
    "    # print(\"endtest\")   \n",
    "    return total_loss / len(loader.dataset) ,pearsonr(preds,reals)[0],preds,reals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indices = list(range(len(dataset)))\n",
    "random.shuffle(indices) \n",
    "\n",
    "test_indices = indices\n",
    "\n",
    "print(test_indices)\n",
    "\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "batch_size = 1\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loss,prt,predt,realt = test(test_loader,0)\n",
    "print(myname)\n",
    "print(\"corr test  \",prt)\n",
    "\n",
    "print(f'Epoch:  Test Loss: {test_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
